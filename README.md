Flask-Text-Generator-using-Hugging-Face-GPT-2
This is a simple Flask web application that allows users to generate text based on a given prompt using a pre-trained language model from Hugging Face's Transformers library. The model used is GPT-2, a lightweight and efficient open-source model suitable for generating coherent and contextually relevant text.
Features

Web interface with a text input form

GPT-2-based text generation using Hugging Face pipeline

Clean, minimal HTML rendering using Flaskâ€™s render_template_string

Automatically generates up to 100 tokens based on user input

Supports real-time POST request handling and text output display

Technologies Used

Python 3

Flask

Transformers (Hugging Face)

HTML (embedded using render_template_string)

Project Structure

app.py or main.py (Flask application code)

How It Works

User enters a text prompt into the web form.

Upon submission, the app sends the prompt to the GPT-2 generator pipeline.

The model processes the prompt and generates a continuation.

The result is displayed below the input form.

How to Run

Ensure Python 3 is installed.

Install the required libraries:
pip install flask transformers

Save the script as main.py or app.py

Run the app:
python main.py

Open your browser and go to:
http://localhost:5000

Example Prompt
Prompt: "Artificial Intelligence is"
Output: "Artificial Intelligence is one of the most exciting fields of technology today..."

Future Enhancements

Add support for selecting different models (e.g., GPT-Neo, Falcon)

Customize max token length and temperature from the UI

Add output streaming for real-time generation

Save prompt history or allow download of results

Credits
Developed as a lightweight demonstration of Flask web integration with Hugging Face Transformers for text generation tasks.
